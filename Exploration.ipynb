{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "from pandas.api.types import CategoricalDtype\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import linear_model as lm\n",
    "from sklearn import preprocessing as pre\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "import quandl\n",
    "quandl.ApiConfig.api_key = \"tzt74qzzscPX2KqxS_rD\"\n",
    "\n",
    "# Plot settings\n",
    "plt.rcParams['figure.figsize'] = (12, 9)\n",
    "plt.rcParams['font.size'] = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load info for sp500\n",
    "sp500_general = pd.read_csv('constituents.csv')\n",
    "sp500_risks = pd.read_csv('company_risk.csv')\n",
    "sp500 = sp500_general.merge(sp500_risks, how='inner', on='Symbol')\n",
    "\n",
    "# Normalize the Risk Column and remove too-risky values\n",
    "min_max_scaler = pre.MinMaxScaler()\n",
    "sp500['Risk'] = min_max_scaler.fit_transform(sp500['Risk'].values.reshape(-1, 1)).flatten()\n",
    "\n",
    "top = sp500[sp500['Risk'] <= 0.9].iloc[0:100]['Symbol'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = quandl.get_table('WIKI/PRICES',\n",
    "                        qopts = { 'columns': ['ticker', 'date', 'close'] },\n",
    "                        ticker = top,\n",
    "                        date = { 'gte': '2017-01-01', 'lte': '2018-01-02' },\n",
    "                        paginate=True)\n",
    "# data['ticker'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "codebook = dict(enumerate(data['ticker'].astype('category').cat.categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['ticker'] = data['ticker'].astype('category').cat.codes\n",
    "data['day'] = (data['date'] - data['date'].min()).dt.days\n",
    "data = data.drop(['date'], axis=1)\n",
    "data['last_day_close'] = data.groupby(['ticker'])['close'].shift()\n",
    "data['last_day_diff'] = data.groupby(['ticker'])['last_day_close'].diff()\n",
    "data = data.dropna()\n",
    "LAST_DAY = data['day'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>close</th>\n",
       "      <th>day</th>\n",
       "      <th>last_day_close</th>\n",
       "      <th>last_day_diff</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>None</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>46.54</td>\n",
       "      <td>2</td>\n",
       "      <td>47.10</td>\n",
       "      <td>0.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>47.99</td>\n",
       "      <td>3</td>\n",
       "      <td>46.54</td>\n",
       "      <td>-0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>48.14</td>\n",
       "      <td>6</td>\n",
       "      <td>47.99</td>\n",
       "      <td>1.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>48.10</td>\n",
       "      <td>7</td>\n",
       "      <td>48.14</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>49.25</td>\n",
       "      <td>8</td>\n",
       "      <td>48.10</td>\n",
       "      <td>-0.04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ticker  close  day  last_day_close  last_day_diff\n",
       "None                                                   \n",
       "2          0  46.54    2           47.10           0.61\n",
       "3          0  47.99    3           46.54          -0.56\n",
       "4          0  48.14    6           47.99           1.45\n",
       "5          0  48.10    7           48.14           0.15\n",
       "6          0  49.25    8           48.10          -0.04"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ttsplit(df, train_size):\n",
    "    X = df.drop(['close'], axis = 1)\n",
    "    y = df['close']\n",
    "    return train_test_split(X, y, train_size=train_size, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL 1: A Random Forest Regressor\n",
    "def build_random_forest(df):\n",
    "    mean_error = []\n",
    "    sizes = [1/4]\n",
    "    for size in sizes:\n",
    "        xtr, xts, ytr, yts = ttsplit(df, size)\n",
    "\n",
    "        mdl = RandomForestRegressor(n_estimators=1000, n_jobs=-1, random_state=0)\n",
    "        mdl.fit(xtr, ytr)\n",
    "\n",
    "        p = mdl.predict(xts)\n",
    "\n",
    "        error = mean_squared_error(yts, p)\n",
    "        print('RMSE Error: %.5f' % (error))\n",
    "        mean_error.append(error)\n",
    "    print('Mean Error = %.5f' % np.mean(mean_error))\n",
    "    return mdl\n",
    "# forest = build_random_forest(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_linear_regressor_test(df):\n",
    "    X_train, X_test, y_train, y_test = ttsplit(df, 0.25)\n",
    "    \n",
    "    # Fit and predict\n",
    "    model = lm.LinearRegression(fit_intercept=True)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_predicted = model.predict(X_test)\n",
    "    \n",
    "    print(f'The validation RMSE for this model is '\n",
    "          f'{round(mean_squared_error(y_test, y_predicted), 2)}.')\n",
    "\n",
    "    return model\n",
    "# linear = build_linear_regressor_test(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = pre.StandardScaler()\n",
    "\n",
    "def build_elastic_net_predictor(df):\n",
    "    scaler = pre.StandardScaler()\n",
    "    X_train, X_test, y_train, y_test = ttsplit(df, 0.25)\n",
    "    \n",
    "    l1_ratios = np.arange(0, 1.1, .1)\n",
    "    alphas = np.arange(0.1, 200.1, .1)\n",
    "    model = lm.ElasticNetCV(l1_ratio=l1_ratios,\n",
    "                            alphas=alphas,\n",
    "                            cv=5,\n",
    "                            fit_intercept=True,\n",
    "                            max_iter=1000)\n",
    "\n",
    "    # Fit and predict\n",
    "    model.fit(scaler.fit_transform(X_train), y_train)\n",
    "    y_predicted = model.predict(scaler.fit_transform(X_test))\n",
    "\n",
    "    print(f'The validation RMSE for this model with '\n",
    "          f'alpha={round(float(model.alpha_), 2)} is '\n",
    "          f'{round(mean_squared_error(y_test, y_predicted), 2)}.')\n",
    "    \n",
    "    return model\n",
    "# elastic = build_elastic_net_predictor(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_future_stock_values(mdl, source_df, days_out):\n",
    "    abs_day = LAST_DAY + days_out\n",
    "    # Warning: Columns must be ordered properly for predictor to work!\n",
    "    tickers = source_df['ticker'].unique()\n",
    "    days = np.arange(LAST_DAY + 1, abs_day + 1, 1)\n",
    "\n",
    "    x = source_df.copy()\n",
    "    for d in days:\n",
    "        print(\"DAY {}\".format(d))\n",
    "        \n",
    "        # Construct a dataframe for the next day, borrowing appropriate values.\n",
    "        i = x[x['day'] == x['day'].max()]\n",
    "        i['day'] += 1\n",
    "        i['last_day_diff'] = i['close'] - i['last_day_close']\n",
    "        i['last_day_close'] = i['close']\n",
    "        i = i.drop(['close'], axis=1)\n",
    "        \n",
    "        # Predict new close values\n",
    "        y = mdl.predict(scaler.fit_transform(i))\n",
    "        i['close'] = pd.Series(y, index=i.index)\n",
    "        \n",
    "        x = x.append(i).sort_values(['ticker', 'day'], ascending=[True, True])\n",
    "        print(x.tail())\n",
    "#     print(x.head())\n",
    "#     return mdl.predict(x)\n",
    "# predict_future_stock_values(elastic, data, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'recommendations': {'BHI': 0.40000000000000002}, 'total': 222.0}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.optimize import linprog\n",
    "\n",
    "# Term is in number of days from current!\n",
    "def suggest_strategy(df, principal, target, term):\n",
    "#     current_day = df['day'].max()\n",
    "    current_day = 0\n",
    "#     elastic = build_elastic_net_predictor(df)\n",
    "#     extended_data = predict_future_stock_values(elastic, df, term) #extended_data has predictions for future\n",
    "    extended_data = df\n",
    "    \n",
    "    period = extended_data[(extended_data['day'] >= current_day) & (extended_data['day'] <= current_day + term)]\n",
    "    stocks_with_current_price = period.groupby('ticker').agg({'close': 'first'})\n",
    "    candidate_stocks = stocks_with_current_price[stocks_with_current_price['close'] <= 2 * principal].index.values\n",
    "    candidate_stock_data = period.loc[period['ticker'].isin(candidate_stocks)]\n",
    "    \n",
    "    c = []\n",
    "    for cs in candidate_stocks:\n",
    "        max_close = candidate_stock_data[candidate_stock_data['ticker'] == cs]['close'].max()\n",
    "        c.append(max_close)\n",
    "    \n",
    "    c = np.array(c)\n",
    "    A_ub = np.array([np.array(stocks_with_current_price.loc[candidate_stocks]['close']), c])\n",
    "    b_ub = np.array([principal, target])\n",
    "    \n",
    "    optimize_result = linprog(-c, A_ub, b_ub)\n",
    "    stock_amounts = {codebook[idx]: amnt for \n",
    "                         idx, amnt in enumerate(np.round(optimize_result.x, decimals=1)) if amnt > 0}\n",
    "\n",
    "    return {\n",
    "        'total': -optimize_result.fun,\n",
    "        'recommendations': stock_amounts\n",
    "    }\n",
    "\n",
    "suggest_strategy(data, 200, 222, 365)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nImprovements:\\n    - Recurrent Neural Network (e.g. LSTM)\\n    - Convert time series to stationary\\n    - Uniform Scaling for each time series\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Improvements:\n",
    "    - Recurrent Neural Network (e.g. LSTM)\n",
    "    - Convert time series to stationary\n",
    "    - Uniform Scaling for each time series\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
